{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjiang10-sv/AiLearning/blob/master/INCS615_Lab3_DetectIntrusionsML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb8-ympJ26uF"
      },
      "source": [
        "# INCS 615 Advanced Network and Internet Security\n",
        "#### Spring 2025, INCS 615-VA1 (2854)\n",
        "#### Instructor: Dr. Zhida Li\n",
        "#### Email: zli74@nyit.edu\n",
        "\n",
        "## Lab #3 (Group) - Detecting Intrusions using Machine Learning Models\n",
        "### Please keep your output when you submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQsXszMj26uL"
      },
      "source": [
        "# Step 1: Load the data, learn the five classes, and count the number of data points for each class\n",
        "Write the Python code:\n",
        "- Load the training and testing data\n",
        "- Count the number of data points for Regular (0), DoS (1), R2L (2), U2R (3), Probe (4) in both training and testing datasets\n",
        "\n",
        "You may use pandas OR numpy for extraction and removing the header:\n",
        "- [_NumPy_](https://numpy.org): used to perform mathematical operations\n",
        "- [_pandas_](https://pandas.pydata.org/): open source data analysis and manipulation tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TqZbcikq2jbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cce958-3f4a-4f40-d9d6-1a26b3a6fbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\Training Dataset:\n",
            "Regular data points: 13449\n",
            "DoS data points: 9234\n",
            "R2L data points: 209\n",
            "U2R data points: 11\n",
            "Probe data points: 2289\n",
            "\n",
            "Testing Dataset:\n",
            "Regular data points: 9711\n",
            "DoS data points: 7460\n",
            "R2L data points: 2885\n",
            "U2R data points: 67\n",
            "Probe data points: 2421\n",
            "Regular data points: 13449\n",
            "DoS data points: 9234\n",
            "R2L data points: 209\n",
            "U2R data points: 11\n",
            "Probe data points: 2289\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# To do...\n",
        "# Load your NSL-KDD training dataset\n",
        "#data_train = pd.read_csv('KDDTrain+_20Percent_615.csv', header=None)\n",
        "data_train = pd.read_csv('KDDTrain+_20Percent_615.csv')  # Keep the header\n",
        "\n",
        "# Load your NSL-KDD testing dataset\n",
        "data_test = pd.read_csv('KDDTest+_615.csv')\n",
        "#data_test = pd.read_csv('KDDTest+_615.csv', header=None)\n",
        "# ...\n",
        "\n",
        "\n",
        "# To do...\n",
        "# Count the number of data points for Regular (0), DoS (1), R2L (2), U2R (3), Probe (4) in both training and testing datasets\n",
        "# training dataset\n",
        "# Count the number of data points for each class in the training dataset\n",
        "num_regular = data_train[data_train.iloc[:, -1] == 0].shape[0]\n",
        "num_dos = data_train[data_train.iloc[:, -1] == 1].shape[0]\n",
        "num_r2l = data_train[data_train.iloc[:, -1] == 2].shape[0]\n",
        "num_u2r = data_train[data_train.iloc[:, -1] == 3].shape[0]\n",
        "num_probe = data_train[data_train.iloc[:, -1] == 4].shape[0]\n",
        "print('\\Training Dataset:')\n",
        "print('Regular data points:', num_regular)\n",
        "print('DoS data points:', num_dos)\n",
        "print('R2L data points:', num_r2l)\n",
        "print('U2R data points:', num_u2r)\n",
        "print('Probe data points:', num_probe)\n",
        "\n",
        "# Count the number of data points for each class in the testing dataset\n",
        "num_regular_test = data_test[data_test.iloc[:, -1] == 0].shape[0]\n",
        "num_dos_test = data_test[data_test.iloc[:, -1] == 1].shape[0]\n",
        "num_r2l_test = data_test[data_test.iloc[:, -1] == 2].shape[0]\n",
        "num_u2r_test = data_test[data_test.iloc[:, -1] == 3].shape[0]\n",
        "num_probe_test = data_test[data_test.iloc[:, -1] == 4].shape[0]\n",
        "\n",
        "print('\\nTesting Dataset:')\n",
        "print('Regular data points:', num_regular_test)\n",
        "print('DoS data points:', num_dos_test)\n",
        "print('R2L data points:', num_r2l_test)\n",
        "print('U2R data points:', num_u2r_test)\n",
        "print('Probe data points:', num_probe_test)\n",
        "print('Regular data points:', num_regular)\n",
        "print('DoS data points:', num_dos)\n",
        "print('R2L data points:', num_r2l)\n",
        "print('U2R data points:', num_u2r)\n",
        "print('Probe data points:', num_probe)\n",
        "\n",
        "# Also testing dataset\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20q6D6wb2jbI"
      },
      "source": [
        "# Step 2: Prepare numerical features\n",
        "Write the Python code:\n",
        "- Select a method and Convert 3 categorical features (“protocol_type”, “service”, and “flag”) to numerical from both training and testing data.\n",
        "  (Data should be numerical when feeding into machine learning models.)\n",
        "\n",
        "You may use pandas OR numpy:\n",
        "- [_NumPy_](https://numpy.org): used to perform mathematical operations\n",
        "- [_pandas_](https://pandas.pydata.org/): open source data analysis and manipulation tool"
      ]
    },
    {
      "source": [
        "categorical_features = [\"protocol_type\", \"service\", \"flag\"]\n",
        "train_df = data_train.copy()\n",
        "test_df = data_test.copy()\n",
        "# n (next): Execute the next line.\n",
        "# s (step): Step into a function call.\n",
        "# c (continue): Continue execution until the next breakpoint or the end of the program.\n",
        "# p (print): Print the value of a variable.\n",
        "# q (quit): Exit the debugger.\n",
        "for feature in categorical_features:\n",
        "    #%debug\n",
        "\n",
        "     # Get column position using iloc\n",
        "    try:\n",
        "        #import pdb; pdb.set_trace()\n",
        "        feature_position = train_df.columns.get_loc(feature)\n",
        "\n",
        "    except KeyError:\n",
        "        print(f\"Feature '{feature}' not found, skipping...\")\n",
        "        continue  # Skip to the next feature\n",
        "\n",
        "    # Generate dummy variables for the training data using iloc\n",
        "    train_dummies = pd.get_dummies(train_df.iloc[:, feature_position], prefix=feature)\n",
        "\n",
        "\n",
        "    # Get the columns to ensure alignment with test data\n",
        "    feature_columns = train_dummies.columns\n",
        "\n",
        "    # Generate dummy variables for the test data\n",
        "    test_dummies = pd.get_dummies(test_df.iloc[:, feature_position], prefix=feature)\n",
        "    # Reindex test dummy columns to match training columns, filling missing with 0\n",
        "    test_dummies = test_dummies.reindex(columns=feature_columns, fill_value=0)\n",
        "\n",
        "    # Drop the original categorical column from both datasets\n",
        "    train_df = train_df.drop(feature, axis=1)\n",
        "    try:\n",
        "        #test_df = test_df.drop(feature, axis=1)\n",
        "        #import pdb; pdb.set_trace()\n",
        "        test_df = test_df.drop(columns=[feature])\n",
        "    except KeyError:\n",
        "        print(f\"Feature '{feature}' not found in test data, skipping...\")\n",
        "        continue  # Skip to the next feature\n",
        "    #test_df = test_df.drop(feature, axis=1)\n",
        "\n",
        "    # Concatenate the dummy variables to the datasets\n",
        "    train_df = pd.concat([train_df, train_dummies], axis=1)\n",
        "    test_df = pd.concat([test_df, test_dummies], axis=1)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pRB2wBUNuULf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzkcEbKo26uL"
      },
      "source": [
        "# Step 3: Nomalize the data and create ML models\n",
        "Write the Python code to:\n",
        "- Normalize the two datasets (training and test data);  \n",
        "- Run a ML model. Various ML algorithms are available in the ML library (https://scikit-learn.org/stable/index.html).\n",
        "\n",
        "If you are running the exercise on your local platform, download and install machine learning (ML) library:  \n",
        "\thttps://scikit-learn.org/stable/index.html\n",
        "\n",
        "The Python libraries installed by [_pip_](https://pip.pypa.io/en/stable/) are:\n",
        "- [_SciPy_](https://scipy.org): dependency of the _scikit-learn_ library.\n",
        "- _SciPy_'s _zscore_: function used to perform normalization.\n",
        "- [_scikit-learn_](https://scikit-learn.org/stable): employed for processing data and calculating performance metrics."
      ]
    },
    {
      "source": [
        "# Import the Python libraries\n",
        "import time\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np #import numpy\n",
        "\n",
        "# Get training and test data and labels for model training\n",
        "# Convert pandas DataFrames to NumPy arrays\n",
        "features_train = train_df.drop(columns=train_df.columns[-1]).values  # Exclude last column (target)\n",
        "labels_train = train_df.iloc[:, -1].values  # Target variable in the last column\n",
        "features_test = test_df.drop(columns=test_df.columns[-1]).values  # Exclude last column (target)\n",
        "labels_test = test_df.iloc[:, -1].values  # Target variable in the last column\n",
        "\n",
        "# Handle NaNs before applying zscore\n",
        "features_train = np.nan_to_num(features_train).astype(np.float64)  # Replace NaNs, convert to float64\n",
        "features_test = np.nan_to_num(features_test).astype(np.float64)  # Replace NaNs, convert to float64\n",
        "\n",
        "# Normalize the training and test datasets using zscore\n",
        "features_train = zscore(features_train, axis=0, ddof=1)\n",
        "features_test = zscore(features_test, axis=0, ddof=1)\n",
        "\n",
        "# Create and train your model\n",
        "time_start = time.time()  # training time - start\n",
        "model = DecisionTreeClassifier()  # Initialize the DecisionTreeClassifier\n",
        "\n",
        "# Generate the model using training data and labels\n",
        "model.fit(features_train, labels_train)\n",
        "\n",
        "time_end = time.time()  # training time - end\n",
        "training_time = time_end - time_start\n",
        "print('Training completed')\n",
        "print('Training time:', training_time)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtHzn7pj4ZWt",
        "outputId": "daf43219-ab20-4da7-c54a-d850573b75a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed\n",
            "Training time: 0.19961309432983398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_nPfWai26uM"
      },
      "source": [
        "# Step 4:\n",
        "Write the Python code to:\n",
        "- Test the developed model on the test dataset named \"features_test\"\n",
        "- Calculate Accuracy and F1-Score based on test labels and predicted labels.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IUGyqCR5Gu9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebd776c-c8fc-43ac-9f56-5d8edfe20b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9905074520936835\n",
            "F1-Score: 0.40555555555555556\n",
            "Taining time: 0.19961309432983398\n"
          ]
        }
      ],
      "source": [
        "# Import the Python libraries\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Testing, for sklearn libriary if applicable\n",
        "predicted_labels = model.predict(features_test)\n",
        "\n",
        "# To do...\n",
        "# Performance metrics\n",
        "accuracy = accuracy_score(labels_test, predicted_labels)\n",
        "fscore = f1_score(labels_test, predicted_labels)\n",
        "\n",
        "# To do...\n",
        "# Show the results: accuracy and training time\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1-Score:', fscore)\n",
        "print('Taining time:', training_time)\n",
        "\n",
        "\n",
        "# Go back to Step 3 to adjust the hyper-parameters and retrain the model, to achieve better results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twHlkCu22jbJ"
      },
      "source": [
        "# Step 5:\n",
        "Write the Python code to:\n",
        "- Select the five most important features with a feature selection algorithm or provide a reasonable explanation.\n",
        "- Re-run the algorithm with the new datasets.\n",
        "- Recalculate the Accuracy and F1-Score and compare these metrics to your previous results."
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# ... (Previous code for data loading, preprocessing, and model training) ...\n",
        "\n",
        "# 1. Feature Selection:\n",
        "# Get feature importances from the trained model\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Get the indices of the top 5 features\n",
        "top_5_feature_indices = np.argsort(feature_importances)[-5:]\n",
        "\n",
        "# Get the names of the top 5 features (if you have feature names)\n",
        "# Assuming 'train_df' has the feature names as columns\n",
        "top_5_feature_names = train_df.columns[top_5_feature_indices]\n",
        "\n",
        "print(\"Top 5 important features:\", top_5_feature_names)\n",
        "\n",
        "# 2. Re-run with Selected Features:\n",
        "# Create new training and testing datasets with only the top 5 features\n",
        "features_train_selected = features_train[:, top_5_feature_indices]\n",
        "features_test_selected = features_test[:, top_5_feature_indices]\n",
        "\n",
        "# Re-train the model with selected features\n",
        "model_selected = DecisionTreeClassifier()\n",
        "model_selected.fit(features_train_selected, labels_train)\n",
        "\n",
        "# 3. Re-calculate Metrics and Compare:\n",
        "# Make predictions on the test set with the selected features\n",
        "predicted_labels_selected = model_selected.predict(features_test_selected)\n",
        "\n",
        "# Calculate Accuracy and F1-Score for the selected features model\n",
        "accuracy_selected = accuracy_score(labels_test, predicted_labels_selected)\n",
        "f1_selected = f1_score(labels_test, predicted_labels_selected, average='weighted')\n",
        "\n",
        "# Print and compare the results\n",
        "print(\"\\nOriginal Model:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1-Score:\", fscore)\n",
        "\n",
        "print(\"\\nSelected Features Model:\")\n",
        "print(\"Accuracy:\", accuracy_selected)\n",
        "print(\"F1-Score:\", f1_selected)\n",
        "\n",
        "# Compare the metrics and analyze the impact of feature selection"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CixOV6S5Fjh",
        "outputId": "288e09d5-3fb4-48c3-e001-4bfcae33cff4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 important features: Index(['service_imap4', 'srv_diff_host_rate', 'dst_host_diff_srv_rate',\n",
            "       'flag_S0', 'serror_rate'],\n",
            "      dtype='object')\n",
            "\n",
            "Original Model:\n",
            "Accuracy: 0.9905074520936835\n",
            "F1-Score: 0.40555555555555556\n",
            "\n",
            "Selected Features Model:\n",
            "Accuracy: 0.9905074520936835\n",
            "F1-Score: 0.9933061398476443\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}